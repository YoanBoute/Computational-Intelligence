{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive(state: Nim) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    genome = {\"love_small\": 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "# Use a cache to improve computation time of this function\n",
    "#analize_cache = dict()\n",
    "def analize(raw: Nim) -> dict:\n",
    "    # global analize_cache\n",
    "    # cached_value = analize_cache.get(raw)\n",
    "    # if cached_value is not None:\n",
    "    #     key = list(analize_cache.keys())[list(analize_cache.values()).index(cached_value)]\n",
    "    #     print(raw, key)\n",
    "    #     return cached_value\n",
    "    # else :\n",
    "        cooked = dict()\n",
    "        cooked[\"possible_moves\"] = dict()\n",
    "        for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "            tmp = deepcopy(raw)\n",
    "            tmp.nimming(ply)\n",
    "            cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "        #analize_cache[raw] = cooked\n",
    "        #print(raw, \"added in cache -->\", cooked)\n",
    "        return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=1, num_objects=3)\n",
      "INFO:root:status: <1 0 5 7 9>\n",
      "INFO:root:ply: player 1 plays Nimply(row=4, num_objects=9)\n",
      "INFO:root:status: <1 0 5 7 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 0 5 7 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=4)\n",
      "INFO:root:status: <0 0 5 3 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=3)\n",
      "INFO:root:status: <0 0 5 0 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=4)\n",
      "INFO:root:status: <0 0 1 0 0>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 0 0 0>\n",
      "INFO:root:status: Player 1 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (pure_random, optimal)\n",
    "\n",
    "nim = Nim(5)\n",
    "logging.info(f\"init : {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "logging.info(f\"status: Player {player} won!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic comparison of strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 131.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 507 , Player 2 : 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(507, 493)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 100 games with the given parameters and print number of victories for each player\n",
    "def compare_strategies(plyr1_strat, plyr2_strat, nim_size) :\n",
    "    strategy = (plyr1_strat, plyr2_strat)\n",
    "    plyr1_victories = 0\n",
    "    plyr2_victories = 0\n",
    "    for _ in tqdm(range(1000)) :\n",
    "        nim = Nim(nim_size)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = strategy[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 0 :\n",
    "            plyr1_victories += 1\n",
    "        else :\n",
    "            plyr2_victories += 1\n",
    "    \n",
    "    results = (plyr1_victories, plyr2_victories)\n",
    "    print(\"Victories -> Player 1 :\", plyr1_victories, \", Player 2 :\", plyr2_victories)\n",
    "    return results\n",
    "\n",
    "compare_strategies(optimal_rule_based1, optimal_rule_based3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First task : Improve rule-based agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_rule_based1(state : Nim) -> Nimply :\n",
    "    # We keep the basic idea : we first have to filter the good moves before selecting one\n",
    "    analysis = analize(state)\n",
    "    good_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "   \n",
    "    # If there is no good move, we can only select one random bad move\n",
    "    if not good_moves:\n",
    "        good_moves = list(analysis[\"possible_moves\"].keys())\n",
    "        ply = random.choice(good_moves)\n",
    "        return ply\n",
    "    \n",
    "    # The best move one can make is the one that lets no good move to their opponent\n",
    "    best_moves = list()\n",
    "    for ply in good_moves :\n",
    "        tmp_nim = deepcopy(state)\n",
    "        tmp_nim.nimming(ply)\n",
    "        opponent_moves = analize(tmp_nim)[\"possible_moves\"]\n",
    "        good_opponent_moves = [ply for ply,ns in opponent_moves.items() if ns != 0]\n",
    "        if not good_opponent_moves :\n",
    "            best_moves.append(ply)\n",
    "    \n",
    "    # If there are best moves, the agent can randomly choose one of them\n",
    "    if len(best_moves) > 0 :\n",
    "        ply = random.choice(best_moves)\n",
    "        return ply\n",
    "    \n",
    "    # If there are no best moves, agent can only choose a good move\n",
    "    ply = random.choice(good_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_rule_based2(state : Nim) -> Nimply :\n",
    "    # We keep the basic idea : we first have to filter the good moves before selecting one\n",
    "    analysis = analize(state)\n",
    "    good_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "   \n",
    "    # If there is no good move, we can only select one random bad move\n",
    "    if not good_moves:\n",
    "        good_moves = list(analysis[\"possible_moves\"].keys())\n",
    "        ply = random.choice(good_moves)\n",
    "        return ply\n",
    "    \n",
    "    # The possible moves are sorted regarding the number of good moves they let to the opponent\n",
    "    sorted_good_moves = PriorityQueue()\n",
    "    for ply in good_moves :\n",
    "        tmp_nim = deepcopy(state)\n",
    "        tmp_nim.nimming(ply)\n",
    "        opponent_moves = analize(tmp_nim)[\"possible_moves\"]\n",
    "        good_opponent_moves = [ply for ply,ns in opponent_moves.items() if ns != 0]\n",
    "        sorted_good_moves.put((len(good_opponent_moves), ply))\n",
    "    \n",
    "    # We always choose the move that lets the lesser good moves to the opponent\n",
    "    _, ply = sorted_good_moves.get()\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_rule_based3(state : Nim) -> Nimply :\n",
    "    # We keep the basic idea : we first have to filter the good moves before selecting one\n",
    "    analysis = analize(state)\n",
    "    good_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "   \n",
    "    # If there is no good move, we can still apply the strategy of taking the move that lets the less godd moves to the opponent\n",
    "    if not good_moves:\n",
    "        good_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    \n",
    "    # The possible moves are sorted regarding the number of good moves they let to the opponent\n",
    "    sorted_good_moves = PriorityQueue()\n",
    "    for ply in good_moves :\n",
    "        tmp_nim = deepcopy(state)\n",
    "        tmp_nim.nimming(ply)\n",
    "        opponent_moves = analize(tmp_nim)[\"possible_moves\"]\n",
    "        good_opponent_moves = [ply for ply,ns in opponent_moves.items() if ns != 0]\n",
    "        sorted_good_moves.put((len(good_opponent_moves), ply))\n",
    "    \n",
    "    # We always choose the move that lets the lesser good moves to the opponent\n",
    "    _, ply = sorted_good_moves.get()\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second task : create an evolutionary agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolutionary_Agent1 :\n",
    "    def __init__(self, nim : Nim) -> None:\n",
    "        self.limit = nim._k if nim._k is not None else np.max(nim.rows)\n",
    "        self.rules = np.array([['np.sum(nim.rows) <=', random.randint(1,50), random.randint(0, len(nim.rows)) - 1, random.randint(1,self.limit)],\n",
    "                      ['np.sum([row for i,row in enumerate(nim.rows) if i % 2 == 1]) <=', random.randint(1,50), random.randint(0, len(nim.rows) - 1), random.randint(1,self.limit)],\n",
    "                      ['np.sum([row for i,row in enumerate(nim.rows) if i % 2 == 0]) <=', random.randint(1,50), random.randint(0, len(nim.rows) - 1), random.randint(1,self.limit)],\n",
    "                      ], dtype=object)\n",
    "    \n",
    "    def default_move(self, nim : Nim) : \n",
    "        ply = Nimply(np.argmax(np.array(nim.rows) != 0), 1)\n",
    "        return ply\n",
    "    \n",
    "    def strategy(self, nim : Nim) :\n",
    "        for rule in self.rules :\n",
    "            if eval(rule[0] + str(rule[1])) :\n",
    "                ply = Nimply(rule[2], rule[3])\n",
    "                # If the move is valid, make it\n",
    "                if nim.rows[ply.row] >= ply.num_objects :\n",
    "                    return ply\n",
    "        # If no valid move was found, make the default move\n",
    "        return self.default_move(nim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent_fitness(agent : Evolutionary_Agent1) :\n",
    "    results = compare_strategies(agent.strategy, optimal_rule_based3, 3)\n",
    "    return results[0]\n",
    "\n",
    "def one_plus_lambda_evolve(agent : Evolutionary_Agent1, lamb : int, nim : Nim) :\n",
    "    num_rows = len(agent.rules)\n",
    "    # TODO : Self-adaptive sigmas\n",
    "    sigmas = np.ones((num_rows, 3))    \n",
    "    agents = [agent]\n",
    "    for _ in range(lamb) :\n",
    "        new_agent = deepcopy(agent)\n",
    "        mutations = np.random.normal(np.zeros((num_rows,3)),np.ones((num_rows,3))).astype(int)\n",
    "        new_agent.rules[:,1:] += mutations\n",
    "        # Prevent invalid mutations from happening (negative thresholds or none object taken)\n",
    "        new_agent.rules[:,1:] = np.maximum([[0,0,1] for _ in range(num_rows)], new_agent.rules[:,1:])\n",
    "        new_agent.rules[:,1:] = np.minimum([[np.sum(nim.rows), num_rows - 1, np.argmax(nim.rows)] for _ in range(num_rows)], new_agent.rules[:,1:])\n",
    "        agents.append(new_agent)\n",
    "    \n",
    "    fitness = []\n",
    "    for a in agents :\n",
    "        fitness.append(evaluate_agent_fitness(a))\n",
    "    \n",
    "    return agents[np.argmax(fitness)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 326.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 353.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 355.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 213.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 234.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 412.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 414.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 407.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 394.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 385.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 395.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victories -> Player 1 : 0 , Player 2 : 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nim = Nim(3)\n",
    "test = Evolutionary_Agent1(nim)\n",
    "new_test = one_plus_lambda_evolve(test, 10, nim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36645553,  1.15063815, -1.38711325],\n",
       "       [-1.03914014, -1.5501803 , -1.75795627],\n",
       "       [ 1.10735406,  0.14152366, -0.49839743]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(np.zeros((len(test.rules),3)),np.ones((len(test.rules),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = (0,3,0)\n",
    "np.argmax(np.array(tab) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
