{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from game import Game, Player, Move, Board\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Game()\n",
    "g.get_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Naive scoring function that considers only the maximum number of cubes of the player aligned'''\n",
    "def naive_score(player, state : Board) :\n",
    "    board = state.board\n",
    "    score = 5\n",
    "    for row in board :\n",
    "        new_score = np.count_nonzero(row == player)\n",
    "        score = min(score, 5 - new_score)\n",
    "    \n",
    "    for col in range(board.shape[1]) :\n",
    "        new_score = np.count_nonzero(board[:,col] == player)\n",
    "        score = min(score, 5 - new_score)\n",
    "    \n",
    "    diag1 = board.diagonal()\n",
    "    new_score = np.count_nonzero(diag1 == player)\n",
    "    score = min(score, 5 - new_score)\n",
    "\n",
    "    diag2 = np.fliplr(board).diagonal()\n",
    "    new_score = np.count_nonzero(diag2 == player)\n",
    "    score = min(score, 5 - new_score)\n",
    "\n",
    "    return score\n",
    "\n",
    "'''Imrovement of naive score, that takes into account the score for the opponent --> The better the score of the opponent, the lesser the score of the state for the player'''\n",
    "def naive_score_consider_opponent(player, state : Board) :\n",
    "    player_score = naive_score(player, state)\n",
    "    opponent_score = naive_score(1 - player, state)\n",
    "    score = player_score + opponent_score\n",
    "\n",
    "    return score\n",
    "\n",
    "def score_avoid_opponent_victory()\n",
    "\n",
    "def score_miminum_to_win(player, state : Board) :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periphery_board(board) :\n",
    "    shape_y, shape_x = board.shape\n",
    "    periphery_cubes = set()\n",
    "    for i in range(shape_x) :\n",
    "        periphery_cubes.add((0,i))\n",
    "        periphery_cubes.add((shape_y-1,i))\n",
    "    for j in range(shape_y) :\n",
    "        periphery_cubes.add((j,0))\n",
    "        periphery_cubes.add((j, shape_x-1))\n",
    "    \n",
    "    return periphery_cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successors(player, board : Board) :\n",
    "    '''Check which cube can be played'''\n",
    "    playable_cubes = []\n",
    "    for pos in get_periphery_board(board) :\n",
    "        if board[pos] == -1 or board[pos] == player :\n",
    "            playable_cubes.append(pos)\n",
    "    \n",
    "    '''For each playable cube, compute the possible successors, depending on the movement of slide, and returns the move and the associated board'''\n",
    "    successors = []\n",
    "    for pos in playable_cubes :\n",
    "        for slide_direction in board.acceptable_slides(pos) :\n",
    "            new_board = deepcopy(board)\n",
    "            new_board[pos] = player\n",
    "            new_board.slide(pos, slide_direction)\n",
    "            # Coordinates are inverted in the Game class, so they are returned inverted here for conversion\n",
    "            successors.append([((pos[1], pos[0]), slide_direction), new_board.board])\n",
    "        \n",
    "    return successors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree :\n",
    "    def __init__(self, board = None, children : list = None) -> None:\n",
    "        self.board = board\n",
    "        self.children = children if children is not None else dict()\n",
    "        # Moves are the plays corresponding one to one to the children boards\n",
    "        self.score = -1        \n",
    "    \n",
    "    def get_leaves(self) :\n",
    "        if self.children == dict() :\n",
    "            return [self]\n",
    "        leaves = []\n",
    "        for move, node in self.children.items() :\n",
    "            leaves.extend(node.get_leaves())\n",
    "        \n",
    "        return leaves\n",
    "    \n",
    "'''Computes all the next possible moves and boards until a given depth is reached, for further application of MinMax.\n",
    "Because of the time limit, the tree is generated in breadth-first, to have in the end as much as possible a tree with all branches being the same size'''\n",
    "def get_states_tree(player : int, board : Board, max_time : int, start_time = None) :\n",
    "    if start_time is None :\n",
    "        start_time = time()\n",
    "    \n",
    "    root = Tree(board)\n",
    "    depth = 0\n",
    "   \n",
    "    # The Queue structure is not really fitting here, as we need to access elements in the middle of it to check for the time constraint\n",
    "    queue = []\n",
    "    queue.append((root, depth))\n",
    "\n",
    "    explored_in_current_depth = 0\n",
    "    while len(queue) != 0 :\n",
    "        # We check if the execution time is above the limit, and if it is the case we accept to finish the current depth only if at least half of it has been explored\n",
    "        # If that is not the case, the tree is returned as such, with branches of differnet lengths\n",
    "        if (time() - start_time) > max_time :\n",
    "            # remaining_in_current_depth = np.count_nonzero(np.array(queue)[:,1] == depth)\n",
    "            # if remaining_in_current_depth > explored_in_current_depth :\n",
    "                break\n",
    "            \n",
    "        old_depth = depth\n",
    "        tree, depth = queue.pop(0)\n",
    "\n",
    "        if tree.board.check_winner() != -1 :\n",
    "            continue\n",
    "        \n",
    "        if depth != old_depth :\n",
    "            player = 1 - player\n",
    "            explored_in_current_depth = 1\n",
    "        else :\n",
    "            explored_in_current_depth += 1\n",
    "\n",
    "        for move, succ in get_successors(player, tree.board) :\n",
    "            child = Tree(Board(succ))\n",
    "            tree.children[move] = child\n",
    "            queue.append((child, depth + 1))\n",
    "            \n",
    "    return root\n",
    "\n",
    "'''Computes the score of the leaves of the tree (furthest anticipated moves) for further application of MinMax'''\n",
    "def valuate_tree(player : int, states_tree : Tree, score_function = score) :\n",
    "    valuated_tree = deepcopy(states_tree)\n",
    "    for leaf in valuated_tree.get_leaves() :\n",
    "        leaf.score = score(player, leaf.board)\n",
    "    \n",
    "    return valuated_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Game()\n",
    "t = get_states_tree(0, Board(g.get_board()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MinMax Algorithm where the root node is always the player who tries to maximize the score --> Returns the Move as well as the score, as we want to know what to play'''\n",
    "def min_max(valuated_tree : Tree, compute_max=False) :\n",
    "    if valuated_tree.children == dict() :\n",
    "        return None, valuated_tree.score\n",
    "    \n",
    "    options = []\n",
    "    for move, child in valuated_tree.children.items() :\n",
    "        options.append([move, min_max(child, compute_max=bool(1-compute_max))[1]])\n",
    "    \n",
    "    if compute_max :\n",
    "        return max(options, key = lambda t : t[1])\n",
    "    else : \n",
    "        return min(options, key = lambda t : t[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxPlayer(Player) :\n",
    "    def __init__(self, score_function) -> None:\n",
    "        super().__init__()\n",
    "        self.score_function = score_function\n",
    "    \n",
    "    def make_move(self, game: Game) -> tuple[tuple[int, int], Move]:\n",
    "        board = Board(game.get_board())\n",
    "        player = game.get_current_player()\n",
    "        tree = get_states_tree(player, board, 0.5)\n",
    "        value_tree = valuate_tree(player, tree, self.score_function)\n",
    "        move, score = min_max(value_tree)\n",
    "        return move\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1,  0,  0],\n",
       "       [-1, -1, -1, -1, -1],\n",
       "       [ 0,  1, -1,  0,  1],\n",
       "       [ 0,  1, -1, -1,  0],\n",
       "       [ 1,  1,  1,  1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import RandomPlayer\n",
    "\n",
    "g = Game()\n",
    "g.play(RandomPlayer(), MinMaxPlayer(naive_score))\n",
    "g.get_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simulates a certain number of games between two strategies, and displays the final performance of both strategies. To avoid potential edge associated to being the beginning player, player1 plays half the time first, half the time second.'''\n",
    "def evaluate_strategies(player1 : Player, player2 : Player, deterministic_only = False) :\n",
    "    # If at least one strategy includes randomness, we run 100 games to get reliable results\n",
    "    if not deterministic_only :\n",
    "        number_of_games = 100\n",
    "    # If both strategies are deterministic, then running several games won't change anything in the results (we only need to play 2 games, one for each starting position)\n",
    "    else :\n",
    "        number_of_games = 2\n",
    "    half_games = number_of_games // 2\n",
    "    victories_1 = victories_2 = 0\n",
    "    for _ in tqdm(range(half_games)) :\n",
    "        g = Game()\n",
    "        g.play(player1, player2)\n",
    "        if g.check_winner() == 0 :\n",
    "            victories_1 += 1\n",
    "        else : \n",
    "            victories_2 += 1\n",
    "    \n",
    "    for _ in tqdm(range(half_games)) :\n",
    "        g = Game()\n",
    "        g.play(player2, player1)\n",
    "        if g.check_winner() == 1 :\n",
    "            victories_1 += 1\n",
    "        else :\n",
    "            victories_2 += 1\n",
    "    \n",
    "    return victories_1, victories_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d811017a4546a2b24213417a040bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_strategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMinMaxPlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRandomPlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [90]\u001b[0m, in \u001b[0;36mevaluate_strategies\u001b[1;34m(player1, player2, deterministic_only)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(half_games)) :\n\u001b[0;32m     12\u001b[0m     g \u001b[38;5;241m=\u001b[39m Game()\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g\u001b[38;5;241m.\u001b[39mcheck_winner() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m     15\u001b[0m         victories_1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Documents\\PoliTo\\Computational Intelligence\\Code\\Computational-Intelligence-RepoGit\\Project_Quixo\\game.py:104\u001b[0m, in \u001b[0;36mGame.play\u001b[1;34m(self, player1, player2)\u001b[0m\n\u001b[0;32m    102\u001b[0m ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[1;32m--> 104\u001b[0m     from_pos, slide \u001b[38;5;241m=\u001b[39m \u001b[43mplayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_player_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_move\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__move(from_pos, slide, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_player_idx)\n\u001b[0;32m    106\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_winner()\n",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36mMinMaxPlayer.make_move\u001b[1;34m(self, game)\u001b[0m\n\u001b[0;32m      7\u001b[0m board \u001b[38;5;241m=\u001b[39m Board(game\u001b[38;5;241m.\u001b[39mget_board())\n\u001b[0;32m      8\u001b[0m player \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_current_player()\n\u001b[1;32m----> 9\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43mget_states_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m value_tree \u001b[38;5;241m=\u001b[39m valuate_tree(player, tree, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_function)\n\u001b[0;32m     11\u001b[0m move, score \u001b[38;5;241m=\u001b[39m min_max(value_tree)\n",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36mget_states_tree\u001b[1;34m(player, board, max_time, start_time)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queue) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# We check if the execution time is above the limit, and if it is the case we accept to finish the current depth only if at least half of it has been explored\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# If that is not the case, the tree is returned as such, with branches of differnet lengths\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m>\u001b[39m max_time :\n\u001b[1;32m---> 35\u001b[0m         remaining_in_current_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m depth)\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining_in_current_depth \u001b[38;5;241m>\u001b[39m explored_in_current_depth :\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_strategies(MinMaxPlayer(), RandomPlayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board(np.array([[ 0, -1, -1, -1, -1],\n",
    " [ 0, -1, -1, -1, -1],\n",
    " [-1, -1, -1, -1, -1],\n",
    " [-1, -1, -1, -1, -1],\n",
    " [ 1, -1, -1, -1, -1]]))\n",
    "\n",
    "t = get_states_tree(1, board, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = valuate_tree(1, t, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = min_max(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1705712649.1574888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO :\n",
    "- ~~In get_successors, return the Moves associated to the next boards~~\n",
    "- ~~Store the Move associated to the Board in the Tree (In the form of a Dict[move : child])~~\n",
    "- ~~Change MinMax to work on dict[child : score of MinMax] to be able to return a direct child of the root and not a leaf of the tree~~\n",
    "- ~~Optimize trees generation to have quicker games (Try caching and/or combine tree generation and valuation to have Alpha-Beta pruning during generation)~~\n",
    "- ~~Change the generation of trees to be in breadth-first, with only time-limit, no more depth limit~~\n",
    "- Improve score function to be more performant\n",
    "    - Number of cubes controlled in the periphery\n",
    "    - Compute the actual minimal number of moves to win, rather than just the maximum number of aligned cubes\n",
    "    - Do the same with consideration for the score of the opponent\n",
    "    - Also grant bonus points for the number of controlled cubes in the inner square (+ extra bonus for center)\n",
    "    - Same with opponent\n",
    "    - Consider additionnally the number of lines started at the same time (started = more than 3 aligned cubes ?) / Compute the average minimum number of moves to win on each possible line\n",
    "    - Same with opponent\n",
    "- ~~See if it is possible to adapt the max_depth of the Tree based on the device capabilities~~\n",
    "- Add the possibility to play against AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 0), <Move.BOTTOM: 1>), 4]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Game()\n",
    "t = get_states_tree(0, Board(g.get_board()), 2, 0)\n",
    "v = valuate_tree(0, t)\n",
    "min_max(v, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 0), <Move.BOTTOM: 1>), 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = np.array([[ 0, 0, 0, 1,-1],\n",
    "                  [ 1,-1,-1,-1, 0],\n",
    "                  [ 0, 1, 1,-1,-1],\n",
    "                  [ 1, 0,-1,-1,-1],\n",
    "                  [ 0, 1, 1, 0,-1]])\n",
    "t = get_states_tree(0, Board(board), 3, 0)\n",
    "v = valuate_tree(0, t)\n",
    "min_max(v, compute_max=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "s = get_states_tree(0, Board(board), 3, 0)\n",
    "v = valuate_tree(0,s)\n",
    "for succ in v.children.items() :\n",
    "    print(succ[1].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer(Player) :\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def make_move(self, game: Game) -> tuple[tuple[int, int], Move]:\n",
    "        print(f\"Turn : Player {game.get_current_player()}\")\n",
    "        print(game.get_board())\n",
    "        x = int(input(\"X\"))\n",
    "        y = int(input(\"Y\"))\n",
    "        pos = (y,x)\n",
    "        move = input('Move')\n",
    "        if move == 't' :\n",
    "            true_move = Move.TOP\n",
    "        elif move == 'r' :\n",
    "            true_move = Move.RIGHT\n",
    "        elif move == 'b' :\n",
    "            true_move = Move.BOTTOM\n",
    "        elif move == 'l' :\n",
    "            true_move = Move.LEFT\n",
    "\n",
    "        return (pos, true_move)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn : Player 0\n",
      "[[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]]\n",
      "Turn : Player 0\n",
      "[[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]]\n",
      "Turn : Player 1\n",
      "[[-1  0 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]]\n",
      "Turn : Player 0\n",
      "[[ 1  0 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]]\n",
      "Turn : Player 1\n",
      "[[ 1  0 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]]\n",
      "Turn : Player 0\n",
      "[[ 1  0 -1 -1 -1]\n",
      " [ 0 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  0 -1 -1 -1]\n",
      " [ 0  0 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1  1]]\n",
      "Turn : Player 0\n",
      "[[ 1  0 -1 -1  1]\n",
      " [ 0  0 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  0 -1 -1  1]\n",
      " [ 0  0 -1 -1 -1]\n",
      " [-1 -1 -1 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1  1]]\n",
      "Turn : Player 0\n",
      "[[ 1  1 -1 -1  1]\n",
      " [ 0  0 -1 -1 -1]\n",
      " [-1  0 -1 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0 -1 -1 -1]\n",
      " [-1  0 -1 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1  1]]\n",
      "Turn : Player 0\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0 -1 -1 -1]\n",
      " [-1  0 -1 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 1 -1 -1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1 -1]\n",
      " [-1  0 -1 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 1 -1 -1 -1  1]]\n",
      "Turn : Player 0\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1  1]\n",
      " [-1  0 -1 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 1 -1 -1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1  1]\n",
      " [-1  0  0 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 1 -1 -1 -1  1]]\n",
      "Turn : Player 0\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1  1]\n",
      " [-1  0  0 -1  0]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [ 1  1 -1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1  1]\n",
      " [-1  0  0 -1  0]\n",
      " [-1 -1  0 -1 -1]\n",
      " [ 1  1 -1 -1  1]]\n",
      "Turn : Player 0\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1  1]\n",
      " [-1  0  0 -1  0]\n",
      " [-1 -1  0 -1 -1]\n",
      " [ 1  1  1 -1  1]]\n",
      "Turn : Player 1\n",
      "[[ 1  1  0 -1  1]\n",
      " [ 0  0  0 -1  1]\n",
      " [-1  0  0 -1  0]\n",
      " [ 0 -1 -1  0 -1]\n",
      " [ 1  1  1 -1  1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Game()\n",
    "g.play(HumanPlayer(), HumanPlayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
